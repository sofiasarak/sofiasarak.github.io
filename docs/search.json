[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "resource description"
  },
  {
    "objectID": "resources.html#fake-resource-number-one",
    "href": "resources.html#fake-resource-number-one",
    "title": "Resources",
    "section": "",
    "text": "resource description"
  },
  {
    "objectID": "resources.html#fake-resource-numbebr-two",
    "href": "resources.html#fake-resource-numbebr-two",
    "title": "Resources",
    "section": "fake resource numbebr two",
    "text": "fake resource numbebr two\nresource description\n\nthis is an h1 element\n\n\nthis is an h1 element with the title class\n\n\nthis paragraph is orange\n\n\nthis text is centered\n\n\nthis text is both centered and orange\n\n\ndescribing something fun that I enjoy doing\nHere’s a full line\n\nHere’s one time line\nHere’s another line\n\n\nThis is centered"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\n\n\nUniversity of California, Santa Barbara (2026), Master of Environmental Data Science\n\nGroup Capstone Project: TBD\n\nWesleyan University (2025), Bachelor of Arts in Earth & Environmental Sciences, Economics\n\nGroup Capstone Project: “Ants, Plants, and Isotopes: Investigating the Trophic Levels of Guanica Dry Forest”\nRelevant Coursework: Soils, Sedimentology, Renewable Energy, Environmental and Resource Economics\n\nStudy Abroad\n\n\nUniversity of Otago (Fall 2024)\n\nCourses:\n\nLa Universidad del San Francisco de Quito (January 2024)\n\nCourse:\n\nResearch and Professional Experience"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html",
    "href": "blog/aquaculture-suitability/index.html",
    "title": "Where Can I Farm this Marine Species?",
    "section": "",
    "text": "In the growing world of aquaculture, knowing where a species will thrive is vital. The subsequent analysis aims to determine which areas of the west coast of the United States are the best suited for a variety of aquaculture species. This is done through the utilization of spatial raster and vector data as well as species-specific requirements.\nThe two main requirements that this analysis takes into consideration is depth and temperature (using sea surface temperature as a proxy), as many marine species can only thrive in certain conditions. Our area of interest is split into zones in order to rank which stretches of the coastline are best and worst suited to house certain species.\nThis sort of analysis is significant in the face of the growing global population and climate change, which has placed a strain on agriculture worldwide. Aquaculture has been growing for years, and expanding development in a thoughtful and sustainable way could contribute to more efficient food production. More production increases food security, as well as contributes to economic growth within communities (Subasinghe et al. 2009).\nIn this blog post you will find an example analysis based on oysters, as well as the creation of a function that takes temperature and depth as arguments and can locate where those conditions are true.\nComplete code for this analysis can be found in the corresponding Github repository."
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#setup",
    "href": "blog/aquaculture-suitability/index.html#setup",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Setup",
    "text": "Setup\n\nlibrary(terra)\nlibrary(sf)\nlibrary(here)\nlibrary(tmap)\nlibrary(tidyverse)"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#data-description-and-import",
    "href": "blog/aquaculture-suitability/index.html#data-description-and-import",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Data Description and Import",
    "text": "Data Description and Import\nSea Surface Temperature\nThis analysis will use average annual sea surface temperature (SST) from the years 2008 to 2012. The data was originally generated from NOAA’s 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1.\nEach year of SST exists in its own raster file. In order to read them in at the same time, I created a for loop based on their standardized naming convention. It is also possible to simultaneously load in and stack multiple raster files using the rast() function, but I preferred the for loop method in my workflow!\n\n\nCode\n# Create a vector of the years we have rasters for (what we will iterate over)\nyears &lt;- c(2008, 2009, 2010, 2011, 2012)\n\n# Initialize empty vectors for for loop\nraster_names &lt;- c()\nfile_paths &lt;- c()\n\n# for loop follows the following steps:\n#   - iterates over the sequence in years vector\n#   - for each year, creates a variable name including the year\n#   - for each year, creates a file path\n#   - assigns the variable name to the raster, which is read in via the created file path\nfor (i in seq(years)){                                      \n  raster_names[i] &lt;- paste0(\"sst_\", years[i])\n  file_paths[i] &lt;- paste0(\"blog/aquaculture-suitability/data/average_annual_sst_\", years[i], \".tif\")\n  \n  assign(raster_names[i], rast(here(file_paths[i])))\n}\n\n# Create raster stack (would throw error if extent, CRS, or resolution don't match)\nsst &lt;- c(sst_2008, sst_2009, sst_2010, sst_2011, sst_2012)\n\n\nBathymetry\nBathymetry, or ocean depth data, is provided in meters from the General Bathymetric Chart of the Oceans (GEBCO). It exists as one raster.\n\n\nCode\n# Use terra package to load in raster\ndepth &lt;- rast(here(\"blog/aquaculture-suitability/data/depth.tif\"))\n\n\nExclusive Economic Zones\nAn Exclusive Economic Zone (EEZ) is “an area of coastal water and seabed within a certain distance of a country’s coastline, to which the country claims exclusive rights for fishing, drilling, and other economic activities” (Oxford Languages).\nOur EEZ data is specifically for the west coast of the United States and comes from Marineregions.org, and contains polygons delineating each of the five zones.\n\n\nCode\n# Use stars package to load in shape data frame\n# quiet = TRUE argument removes output/message\neez &lt;- st_read(here(\"blog/aquaculture-suitability/data/wc_regions_clean.shp\"), quiet = TRUE)"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#preparing-and-processing-data",
    "href": "blog/aquaculture-suitability/index.html#preparing-and-processing-data",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Preparing and Processing Data",
    "text": "Preparing and Processing Data\nIn order to proper perform analyses using all of data sets, we need to ensure that they all have matching CRSs, and transform them if otherwise. Additionally, for our analysis we will use the mean SST over the years 2008-2012 in Celsius, so we can calculate that.\n\n\nCode\n# Project depth raster to match CRS of sst raster\ndepth &lt;- project(depth, crs(sst))\n\n# Project (using the stars package) to match the CRS of sst raster\neez &lt;- st_transform(eez, crs(sst))\n\n\n\n# mean() operation on raster of multiple layers creates object with one raster layer\nmean_sst &lt;- mean(sst)\n# Subtract 273.15 (conversion from K to C) from all pixels\nmean_sst_c &lt;- mean_sst - 273.15\n\nWe want to combine our sst and depth data, but in order to do so, we have to ensure they have the same extent, resolution, and position.\nTo handle differences in the extent, we can crop depth to match sst. And to fix the issue of mismatched resolutions, we can re-sample the depth data to match the resolution of sst.\nRe-sampling is the method by which we can compute values for new pixel locations in depth based on custom resolutions and origins. We will use the “nearest neighbor approach”, a technique in which the value of each cell in the output raster (in this case, depth_cropped) is calculated using the value of the nearest cell in the input raster (mean_sst) (ESRI GIS Dictionary). This fills in the new cells that will be created in order for depth to match the resolution of sst.\n\n\nCode\n# Crop depth raster to limits of sst raster\ndepth_cropped &lt;- crop(depth, y = mean_sst_c)\n\n# Resample depth data to match specifications of sst data, specifying nearest neighbor method\ndepth_cropped_resampled &lt;- resample(depth_cropped, y = mean_sst_c, method = \"near\")\n\n\nA way to know if we have succeeded in matching the extent, resolution, and position of our two rasters is by seeing if they will stack or not. If they do not completely match, an error will be thrown and stacking will fail.\n\ndepth_sst &lt;- c(depth_cropped_resampled, mean_sst_c)\n\nWe successfully stacked our two rasters!"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#finding-areas-with-suitable-growing-conditions-oysters",
    "href": "blog/aquaculture-suitability/index.html#finding-areas-with-suitable-growing-conditions-oysters",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Finding Areas with Suitable Growing Conditions: Oysters",
    "text": "Finding Areas with Suitable Growing Conditions: Oysters\n\n\n\n\n\n\nFigure 1: Cages are a method used for oyster farming (Image Source: Pangea Shellfish Company).\n\n\n\nResearch has shown that oysters need the following conditions for optimal growth:\n\ndepth: 0-70 meters below sea level (or -70 in our data)\nsea surface temperature: 11-30°C\n\nThese specifications can be retrieved from resources such as SeaLifeBase.\nIn order to find the areas with suitable growing conditions for oysters, we will assign a value of 1 to each pixel that is within the suitable range and 0 otherwise, for both of our separate raster layers.\n\n\nCode\n# Change layer names to be more indicative (\"mean\" --&gt; \"sst_mean\")\nnames(depth_sst) &lt;- c(\"depth\", \"sst_mean_c\")\n\n# Create copy of data frame to serve as mask\ndepth_sst_mask &lt;- depth_sst\n\n# Create suitability matrix based on min and max sst \nsst_suitability &lt;- matrix(c(-Inf, 11, 0,  # Will return 0 for values (-Inf, 11)\n                          11, 30, 1,      # Will return 1 for values (11, 30)\n                          30, Inf, 0),    # Will return 0 for values (30, Inf)\n                          nrow = 3, byrow = TRUE)\n\n# Classify sst layers using matrix\ndepth_sst_mask[[\"sst_mean_c\"]] &lt;- classify(depth_sst_mask[[\"sst_mean_c\"]], rcl = sst_suitability)\n\n# Create suitability matrix based on min and max sst \ndepth_suitability &lt;- matrix(c(-Inf, -70, 0,\n                              -70, 0, 1,\n                              0, Inf, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Classify depth layers using matrix\ndepth_sst_mask[[\"depth\"]] &lt;- classify(depth_sst_mask[[\"depth\"]], rcl = depth_suitability)\n\n\nThen,to create one suitability layer that contains suitability based on both variables, we will multiply the two layers, obtaining the following results:\n\nif a cell = 1, it is suitable based on both conditions\nif a cell = 0, it is not suitable (either based on one of or both conditions)\n\nThis can be true because anything multiplied by 0 (not suitable in this case), will equal 0. If at least one of our layers contains 0, our new suitability layer will also contain the value 0. Cells that are suitable for both SST and depth will be the only ones that contain 1 as their value.\n\n\nCode\n# Multiply two layers and save as a new raster\noyster_suitability &lt;- depth_sst_mask[[\"depth\"]] * depth_sst_mask[[\"sst_mean_c\"]]\n\n# Rename raster layer to be more indicative (\"depth\" --&gt; \"suitable\")\nnames(oyster_suitability) &lt;- c(\"suitable\")"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#determining-the-most-suitable-eez",
    "href": "blog/aquaculture-suitability/index.html#determining-the-most-suitable-eez",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Determining the Most Suitable EEZ",
    "text": "Determining the Most Suitable EEZ\nWe want to determine the total suitable area within each EEZ in order to rank zones by priority.\nThis requires three distinct steps:\n\nFind the number of cells within each zone that are deemed suitable (based on previous analysis).\nFind the physical area that each cell represents (in km^2).\nMultiply number of cells by area that cells represent to get actual suitable area, by zone.\n\n\n# Create a raster of species suitability only within the EEZ boundaries\nsuitable_westcoast &lt;- mask(oyster_suitability, eez)\n\n# Rasterize EEZ (will allow for zonal operations)\neez_rast &lt;- rasterize(eez, suitable_westcoast,\n                      field = \"rgn\")      # Set region as the value we want populating the EEZ raster\n\nWe can find the number of suitable cells in each EEZ region by using the terra::zonal function. It summarizes values of one SpatRaster based on the zones provided by another. In our case, we will be summing the values of our suitable cells grouped by EEZ.\nSummation works to provide the number of suitable cells in this case because we had populated suitable with “1”s and unsuitable with “0”s.\n\n# Find the number of suitable cells per EEZ region\nsuitable_per_region &lt;- zonal(suitable_westcoast, eez_rast, fun = \"sum\", na.rm = TRUE)\n\nResults:\n\n\n\nOyster Suitability by Region\n\n\nEEZ\n# of Suitable Cells\n\n\n\n\nCentral California\n238\n\n\nNorthern California\n11\n\n\nOregon\n71\n\n\nSouthern California\n211\n\n\nWashington\n162\n\n\n\n\n\n\nFrom these results, we can then find total suitable area within each region.\n\n\nCode\n# cellSize() returns a SpatRaster object of information, we want to extract just cell area\ncell_area &lt;- cellSize(suitable_westcoast, unit=\"km\")[1]\n\n# Multiply by each region by adding and specifying columns to data frame\nsuitable_per_region &lt;- suitable_per_region %&gt;% \n  mutate(cell_area = cell_area,\n         area_suitable = suitable * cell_area) %&gt;% \n  relocate(cell_area, .after = suitable) \n\n\nIn order to produce a map of West Coast EEZs colored by amount of suitable species area in each region, we need to join our EEZ geometries to our suitable_per_region data frame.\n\n# Join EEZ data frame (with geometries) to data frame with suitable area by region\neez_suitability_geom &lt;- left_join(eez, suitable_per_region, by = \"rgn\")\n\nThe eez_suitability_geom now contains the five West Coast region polygons with their corresponding suitable areas for oysters.\nThe final step of our oyster analysis is to create a map of EEZ regions colored by amount of suitable area. For this, we use our original depth raster to provide a background image (and general outlines of the California coast), overlayed with the 5 West Coast EEZs, colored by amount of suitable area.\n\n\nCode\n# Turn off autoscale -- messes with font size\ntmap_options(component.autoscale = FALSE) \n\n# Create map using tmap\ntm_shape(depth) +                                      # Plot depth raster as first layer\n  tm_raster(col.scale  = tm_scale(values = c(\"steelblue\", \"#84d18d\")),    \n            col.legend = tm_legend(show = FALSE)) +    # Hide depth legend because not of interest\ntm_shape(eez_suitability_geom) +                       # Plot EEZ polygons\n  tm_polygons(fill = \"area_suitable\",                  # Fill by suitable area\n              fill.scale = tm_scale(values = \"brewer.yl_or_rd\"),\n              fill.legend = tm_legend(title = \"Suitable Area (km²)\"),\n              fill_alpha = 0.6,\n              lwd = 0.5) + \n  tm_text(text = \"rgn\",                                # Add EEZ zone labels\n          size = 0.7,\n          xmod = -2.2,\n          col = \"black\",\n          fontface = \"bold\") +\ntm_title(\"Suitability of West Coast EEZs for Oyster Aquaculture\",\n         size = 1)\n\n\n\n\n\n\n\n\n\nFrom this visualization, we can see that – based on suitable depth and sst – Central and Southern California are the best suited for oyster aquaculture compared to the other EEZs of the US West Coast."
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#generalizing-workflow-creating-function",
    "href": "blog/aquaculture-suitability/index.html#generalizing-workflow-creating-function",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Generalizing Workflow (Creating Function)",
    "text": "Generalizing Workflow (Creating Function)\nIn the code above, we developed a method of extracting the most suitable regions for marine aquaculture based on just a few parameters: temperature range and depth range. By making our workflow generalizable, we can create a function that takes a handle of arguments and produces a map of suitable West Coast EEZs for any marine species.\nOur function will assume that the datasets/rasters sst (single layer), depth, and eez are pre-loaded and contain the correct attributes.\nThe other thing to note is that when inputting minimum and maximum depth, we will input the absolute value of depth (so, no negatives), with the larger number being maximum depth. For example, a depth of 70 meters, or 70 meters below sea level, should be entered as 70.\n\n\nCode\n# Initialize function\nwest_coast_suitability_map &lt;- function(species, min_sst, max_sst, min_depth, max_depth){\n\n# Creating depth and sst mask based on min and max values\ndepth_sst_mask &lt;- depth_sst\n\n# sst matrix and classification, using function arguments\nsst_suitability &lt;- matrix(c(-Inf, min_sst, 0,\n                          min_sst, max_sst, 1, \n                          max_sst, Inf, 0),\n                          nrow = 3, byrow = TRUE)\n\ndepth_sst_mask[[\"sst_mean_c\"]] &lt;- classify(depth_sst_mask[[\"sst_mean_c\"]], rcl = sst_suitability)\n\n# depth matrix and classification\ndepth_suitability &lt;- matrix(c(-Inf, -max_depth, 0,\n                              -max_depth, min_depth, 1,\n                               min_depth, Inf, 0),\n                               nrow = 3, byrow = TRUE)\n\ndepth_sst_mask[[\"depth\"]] &lt;- classify(depth_sst_mask[[\"depth\"]], rcl = depth_suitability)\n\n# Creating suitability raster\nsuitability_raster &lt;- depth_sst_mask[[\"depth\"]] * depth_sst_mask[[\"sst_mean_c\"]]\n\n# Renaming raster layer value to be more accurate\nnames(suitability_raster) &lt;- c(\"suitable\")\n\n# Create a raster of species suitability only within the EEZ boundaries\nsuitable_westcoast &lt;- mask(suitability_raster, eez)\n\n# Rasterize EEZ (will allow for zonal operations)\neez_rast &lt;- rasterize(eez, suitable_westcoast,\n                      field = \"rgn\")      # Set region as the value we want populating the EEZ raster\n\n# Find the number of suitable cells per EEZ region\nsuitable_per_region &lt;- zonal(suitable_westcoast, eez_rast, fun = \"sum\", na.rm = TRUE)\n\n# cellSize() returns a SpatRaster object of information, we want to extract just area\ncell_area &lt;- cellSize(suitable_westcoast, unit=\"km\")[1]\n\n# Multiplying by each region by adding and specifying columns to data frame\nsuitable_per_region &lt;- suitable_per_region %&gt;% \n  mutate(cell_area = cell_area,\n         area_suitable = suitable * cell_area) %&gt;% \n  relocate(cell_area, .after = suitable) \n\n# Join eez data frame (with geometries) to data frame with suitable area by region\neez_suitability_geom &lt;- left_join(eez, suitable_per_region, by = \"rgn\")\n\n# Turn off autoscale -- messes with font size\ntmap_options(component.autoscale = FALSE) \n\n# Create map using tmap\nsuitability_map &lt;- tm_shape(depth) +                                      # Plot depth raster as first layer\n  tm_raster(col.scale  = tm_scale(values = c(\"steelblue\", \"#84d18d\")),    \n            col.legend = tm_legend(show = FALSE)) +    # Hide depth legend because not of interest\ntm_shape(eez_suitability_geom) +                       # Plot EEZ polygons\n  tm_polygons(fill = \"area_suitable\",                  # Fill by suitable area\n              fill.scale = tm_scale(values = \"brewer.yl_or_rd\"),\n              fill.legend = tm_legend(title = \"Suitable Area (km²)\"),\n              fill_alpha = 0.6,\n              lwd = 0.5) + \n   tm_text(text = \"rgn\",                                # Add EEZ zone labels\n          size = 0.7,\n          xmod = -2.2,\n          col = \"black\",\n          fontface = \"bold\")+\ntm_title(paste(\"Suitability of West Coast EEZs for\", species, \"Aquaculture\"),\n         size = 1)\n\nreturn(suitability_map)\n}"
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#running-function-on-new-species-bull-kelp",
    "href": "blog/aquaculture-suitability/index.html#running-function-on-new-species-bull-kelp",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Running Function on New Species: Bull Kelp",
    "text": "Running Function on New Species: Bull Kelp\n\n\n\n\n\n\nFigure 2: Bull kelp farming in Alaska (Image Source: aquaculturenorthamerica.com).\n\n\n\nBull kelp farming is a niche sector of seaweed aquaculture, especially small compared to the large seaweed operations taking place in Asia. Currently, there are only a few active, albeit experimental, bull kelp farms in Alaska and BC.\nThis lack of development is partially due to the fact that bull kelp is not necessarily a commercial commodity in the same way other species of seaweed, such as sugar kelp (Sacharrina latissima) or ribbon kelp (Alaria marginata), are. Despite its challenges, bull kelp is essential for ocean health and biodiversity, so farming more of it could help with restoration efforts, as well as help fill knowledge gaps in its cultivation.\nBull kelp’s suitability conditions are as follows:\n\ndepth: 17 to 40 meters\nsea surface temperature: 10 to 16 degrees Celsius\n\n\n# Use function to plot regions with highest suitability\nwest_coast_suitability_map(species = \"Bull Kelp\" ,\n                           min_sst = 10,\n                           max_sst = 16,\n                           min_depth = 40,\n                           max_depth = 17)\n\n\n\n\n\n\n\n\nFrom this visualization, we can see that – based on suitable depth and sea surface temperature – the Washington region is by far the best suited for bull kelp aquaculture compared to the other EEZs of the US West Coast. This agrees with our previous research: if successful bull kelp farms are mostly in Alaska and Canada, it would make sense that the northernmost region would be the most suitable."
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#conclusion",
    "href": "blog/aquaculture-suitability/index.html#conclusion",
    "title": "Where Can I Farm this Marine Species?",
    "section": "Conclusion",
    "text": "Conclusion\nThis blog post used packages such as terra and sf to combine raster and vector data on ocean depth and temperature, and classify different zones along the cost based on specifications. In our case, we were able to determine that the southern California coast is the most suitable for oyster aquaculture whereas the northern coast – specifically the Washington EEZ – is best for bull kelp.\nIt is important to note, however, that sea surface temperature and depth are only two of the many factors that influence aquaculture success. Our analysis not only excludes other variables such as current strength, salinity, and water quality, but also fails to consider future changes to ocean temperature that may be crucial in the planning of aquaculture.\nDespite these caveats, this sort of code is generalizable first step to a variety of uses that involve finding most suitable areas – not just for aquaculture. And especially with the creation of a function, the possibilities are endless."
  },
  {
    "objectID": "blog/aquaculture-suitability/index.html#references",
    "href": "blog/aquaculture-suitability/index.html#references",
    "title": "Where Can I Farm this Marine Species?",
    "section": "References",
    "text": "References\nCalifornia Department of Fish and Wildlife, Marine Species Portal. (n.d.). Kelp and other marine algae — True kelp species in California. Accessed November 20, 2025. https://marinespecies.wildlife.ca.gov/kelp/true/#:~:text=Bull%20kelp%20grows%20on%20similar,and%20on%20wave%2Dexposed%20reefs\nSubasinghe, R., Soto, D., & Jia, J. (2009). Global aquaculture and its role in sustainable development. Reviews in aquaculture, 1(1), 2-9.\nThe Mysterious World of Bull Kelp. (n.d.). Aquaculture. Accessed November 20, 2025. https://bullkelp.info/aquaculture\nWeigel, B. L., Small, S. L., Berry, H. D., & Dethier, M. N. (2023). Effects of temperature and nutrients on microscopic stages of the bull kelp (Nereocystis luetkeana, Phaeophyceae). Journal of phycology, 59(5), 893–907. https://doi.org/10.1111/jpy.13366"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sofia Sarak",
    "section": "",
    "text": "Hello, I do environmental data science!\n\n\nThis website is currently under partial construction (data analysis projects coming soon!).\nFor now, please feel free to browse through my Github and LinkedIn for more on what I do."
  },
  {
    "objectID": "blog/stats-proj/index.html",
    "href": "blog/stats-proj/index.html",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "",
    "text": "The following blog post narrates a statistical analysis performed on water-quality, bed-sediment, and invertebrate tissue trace-element concentrations for tributaries in the Clark Fork Basin, Montana. The use of the Gamma and segmented statistical models aims to confirm or deny the presence of a break-point at which a potential relationship between invertebrate and water trace-element concentrations changes.\nResults such as these have the potential to influence policy decisions regarding water ecosystem rehabilitation, signficant after years of mining and industry pollution in the area."
  },
  {
    "objectID": "blog/stats-proj/index.html#clark-fork-basin-data",
    "href": "blog/stats-proj/index.html#clark-fork-basin-data",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Clark Fork Basin Data",
    "text": "Clark Fork Basin Data\nThis data set is sourced from the USGS National Water Information System database. It contains trace-element concentration values of water, sediment, and species of small invertebrates (caddisflies and stone flies) along the tributaries of the Clark Fork Basin, Montana (collected in July 2021).\n\n\n\n\n\n\n\nCaddisflies are freshwater insects, spending their larval stage in freshwater bodies of water. (Image Source: Shuttershock)\n\n\n\n\n\n\n\n\n\n\n\nClark Fork Basin tributaries in Montana, where data for the subsequent analysis was collected. (Image Source: USGS)\n\n\n\n\n\n\nWater, bed sediment, and invertebrate tissue were sampled in streams that contain trace elements associated with historical mining and smelting activities. Large-scale mining and smelting were prevalent in the basin for more than 100 years but are now either discontinued or reduced in scale. In 2020, land uses were primarily cattle production, logging, mining, residential development, and recreation.\nConcern about the toxicity of trace elements to the aquatic ecosystem and human health has resulted in a comprehensive monitoring effort by State, Federal, Tribal, and private entities to characterize the aquatic resources in the Clark Fork Basin. This effort was designed to guide and monitor remedial activities and to evaluate the effectiveness of remediation and cleanup.\nWater and fine-grained-bed-sediment samples were collected from the streams at multiple depths and, if possible, from both sides of the stream bed. Benthic insects at immature stages were collected with a large nylon-mesh kick net. Trace-element analysis was conducted back in the laboratory. (More details on sampling methods can be found in the original report).\nIn this analysis, we use three elements that were tested across water, sediment, and invertebrate tissue, in an effort to explore the impact of water contamination level on the ecology and food systems of the area. Trace-element concentration in water is treated as the main predictor variable for trace-element concentration in invertebrate tissue. This relationship was determined based on past research which used element accumulation in aquatic larvae as an indicator for water quality (Haas & Pánik 2025, Pastorino et al. 2019).\n\n\n\n\n\n\nFigure 1: Directed Acyclic Graph depicting the relationship between our variables of interest.\n\n\n\nSediment concentration acts as a source of trace-element concentration, as sediment can store and potentially release trace-elements back into water over the long term (Horowitz 1991). Species may have an effect on trace-element accumulation as it can introduce differences in metabolic function, but this will not be explored in this analysis.\n\nData Exploration\nThe following figures are useful to visualize the similarities and differences in distribution of trace-elements across the three sinks (water, sediment, and invertebrate tissue) tested, as well as provide a quick overview of the range that each trace-element spans.\n\n\n\n\n\n\n\n\n\nIt appears that copper and lead have similar distributions between all three sinks, but on widely different scales (sediment holds the most, tissue the second most, and water the least). Arsenic has a wider distribution in water than in sediment and invertebrate tissue.\n\n\n\n\n\n\n\n\n\nConsidering the axes of our plots, we can see that all of our trace-elements exist at varying ranges of concentration in both water and invertebrate tissue. Generally, there appears to be a visual positive relationship (perhaps less so in lead).\n\n\n\n\n\n\n\n\n\nSimilar to the previous figure, we can come to the conclusion that trace-elements occur at different scales. The visual positive relationship between sediment and invertebrate tissue is more obvious across trace-elements than between water and invertebrate tissue."
  },
  {
    "objectID": "blog/stats-proj/index.html#why-gamma-and-segmented-models",
    "href": "blog/stats-proj/index.html#why-gamma-and-segmented-models",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Why Gamma and Segmented Models?",
    "text": "Why Gamma and Segmented Models?\n\nModel 1: Segmented\nThe segmented/break-point (or sometimes referred to as broken-line) statistical model is a regression analysis where the relationship between the response and one or more predictor variables contain a break-point at which the relationship changes. This sort of model is common in fields such as epidemiology, occupational medicine, toxicology, and ecology, where it is of interest to assess threshold value where the effect of the covariate changes.\nWe will use the model in our analysis to explore whether there is a threshold value(s) at which the relationship between trace-element concentration in water and trace-element accumulation in invertebrates changes. This is of interest to us because there are extreme values in the biota trace-element concentrations (depicted by the plots in the previous section), which the Gamma model may not be flexible enough to account for. As well, from a policy perspective, it is important to know whether there are certain thresholds to be reached in terms of rehabilitation of ecological communities.\nTo test this analysis on simulated data, we can do so by feeding it data that has a known break-point, such as that below.\n\n\n\n\n\n\n\n\n\nTo follow the steps of a segmented model, we first apply a linear regression model to the data, then the segmented model.\n\n# Run lm model on data\nsample_model_seg_1 &lt;- lm(data = sample_data, y~x)\n\n# Run segmented model on lm (note: function comes from the R package \"segmented\")\nsample_model_seg_2 &lt;- segmented(sample_model_seg_1, seg.Z = ~x)\n\nIf we were successful, the summary should return an estimated breakpoint at x = 50.\n\n# Does it return a break-point of 50?\nsummary(sample_model_seg_2)$psi\n\n\n\n\n\n\n\n\n\nSegmented Model Summary\n\n\nBreak-point\nInitial\nEst.\nSt. Err\n\n\n\n\npsi1.x\nNA\n50\n4.045619e-15\n\n\n\n\n\n\n\nIt does!\n\n\nModel 2: Gamma\nThe segmented model must be applied to an already existing linear regression model, as it builds off of an already-analyzed relationship between the response and predictor variable(s) — segmented analysis simply determines where the analyzed relationship changes.\nTherefore, for the first step of our analysis we will use a Gamma regression model. It is appropriate for data containing strictly positive continuous variables with a skewed distributions. Our data matches this description, as trace-element concentrations are never negative (and our data contains no values of 0), and higher concentrations occur less frequently than lower ones.\nThe Gamma distribution is made up of the parameters shape and scale, which relate to the mean and variance of the data through the following formulas.\nTo test this analysis on simulated data, we can do so by feeding it data that has a known Gamma distribution, simulated using the rgamma function; this will be the predictor variable. To attain the response variable, we will create a y with known coefficients \\(\\beta_{0}\\) and \\(\\beta_{1}\\). We can then confirm that our analysis worked by returning the summary of the Gamma model, and seeing if the results match our predermined relationship.\n\n# Set Gamma parameters\nm &lt;- 5 # true mean\nv &lt;- 2.5  # true variance\n\n# Set linear model coefficients\nB0 &lt;- 0.5 # beta0\nB1 &lt;- 1 # beta1\n\n# Produce x (gamma distribution) and y (linearly related to x)\nx = rgamma(n = 10000, shape = (m^2)/v, scale = v/m)\ny = B0 + B1 * x\n\n# Create data frame\nsimulated_data &lt;- data.frame(x, y)\n\n\n\n\n\n\n\n\n\n\n\nmodel &lt;- glm(y ~ x, \n          data = simulated_data,\n          family = Gamma(link = \"identity\"))\n\n\n\n\n\n\n\n\n\nGamma Model Summary\n\n\nCoefficients:\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n5.000e-01\n1.678e-16\n2.980e+15\n&lt;2e-16 ***\n\n\nx\n1.000e+00\n3.850e-17\n2.597e+16\n&lt;2e-16 ***\n\n\n\n\n\n\n\nAs we can see in the figure above, our glm(family = 'Gamma') returns the expected coefficients."
  },
  {
    "objectID": "blog/stats-proj/index.html#statistical-model",
    "href": "blog/stats-proj/index.html#statistical-model",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Statistical Model",
    "text": "Statistical Model\nBased on what we know about the Gamma and segmented models, as well as the relationship we wish explore, our model is as follows:\n\\[\n\\text{InvertConc} \\sim \\text{Gamma}(\\mu, \\sigma)\n\\]\n\\[\n\\log(\\mu)\n= \\beta_{0}\n+ \\beta_{1}\\,\\text{WaterConc}\n+ \\beta_{2}\\,\\tau\\text{WaterConc}\\,\n+ \\beta_{3}\\,\\text{SedimentConc}\n\\]\nIn this case, \\(\\tau\\) represents the presence of break-point. It should also be noted that whereas a Gamma distribution uses the parameters shape and scale, a Gamma regression has the paremeters \\(\\mu\\) (mean) and \\(\\sigma\\) (variance). Their relationships with shape and scale are:\n\n\\(\\mu\\) = shape * scale\n\\(\\sigma\\) = shape * (scale)²"
  },
  {
    "objectID": "blog/stats-proj/index.html#hypotheses",
    "href": "blog/stats-proj/index.html#hypotheses",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Hypotheses",
    "text": "Hypotheses\nThrough our multi-step analysis, we aim to answer the following questions:\n\nDoes trace-element concentration in water increase trace-element concentration in macroinvertebrates?\nIs the risk of trace-element contamination/ingestion constant across the whole range of concentrations in sediment and water?\nIf the risk is sediment/water-concentration dependent, does a threshold value exist?\n\nFrom this, we gather two sets of null and alternative hypotheses.\n\nStep 1 (Gamma Model):\nNull Hypothesis: There is no relationship between trace-element concentration in water and biota.\nAlternative Hypthesis: There is a positive relationship between trace-element concentration in water and biota.\n\n\nStep 2 (Segmented Model):\nNull Hypothesis: There is no breakpoint in the relationship between trace-element concentration in water and biota.\nAlternative Hypthesis: There is a breakpoint in the relationship between trace-element concentration in water and biota."
  },
  {
    "objectID": "blog/stats-proj/index.html#the-issue-of-collinearity",
    "href": "blog/stats-proj/index.html#the-issue-of-collinearity",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "The Issue of Collinearity?",
    "text": "The Issue of Collinearity?\nIt is sensible to be wary of both sediment and water trace-element concentration as predictor variables in this model. Wouldn’t they be highly correlated? In fact, no.\nRosso et al. 2012 conducted a study similar to ours that explored arsenic concentrations in water, sediment, and fish species from naturally contaminated rivers. They found that there was little correlation between the concentration of arsenic in the water and the sediment. This may be due to the different storage and cycling mechanisms of the two trace-element sinks.\nTo confirm that we do not face collinearity in our analysis, we find the R² between our water and sediment concentration variables, for all three of our trace-elements. Literature suggests that R² values of 0.8 or below typically give no reason to be concerned about collinearity. The results are summarized below.\n\n\n\n\n\n\n\n\nCorrelation Between Water and Sediment Concentrations\n\n\nTrace-Element\nArsenic\nCopper\nLead\n\n\n\n\nR²\n0.15\n0.39\n0.32\n\n\n\n\n\n\n\nAs all of the R² values between water and sediment concentration are quite low, we can confidently proceed with our two predictor variables."
  },
  {
    "objectID": "blog/stats-proj/index.html#the-analysis",
    "href": "blog/stats-proj/index.html#the-analysis",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "The Analysis",
    "text": "The Analysis\nThis blog post will only feature the code for the trace-element arsenic, but the same steps can be applied to each trace-element (with the exception of values that correspond to range), and will be included in the later interpretation section.\nWe evaluate each trace-element separately (instead of using them as predictor variables in our model) because each element differs in chemical and biological properties. They interact with water, sediment, and biota differently, and the concentration of one does not affect the other in the context of our analysis. Therefore, we can model them each separately.\nAs stated, we explore the effect of trace-element concentration in water on the corresponding concentration in biota tissue, controlling for sediment concentration.\n\nStep 1: Generating models from original data.\n\n# Run Gamma model on arsenic data\nconc_model_gamma &lt;- glm(concentration_biota ~ concentration_water + concentration_sediment, \n                   data = conc_arsenic, \n                   family = Gamma(link = \"log\")) # Log as link function to account for exponential nature of data\n\n# Run segmented model on Gamma model (note: segmented function comes from the \"segmented\" R package)\nconc_model_seg &lt;- segmented(obj = conc_model_gamma, seg.Z = ~ concentration_water + concentration_sediment)\n\n\n\nStep 2: Applying models to generated values.\n\n# Create prediction grid with levels of water and sediment concentrations\npred_grid &lt;- expand_grid(concentration_water = 0:30,\n                         concentration_sediment = 0:150)\n\n# Applying gamma model to simulated values\nconc_model_gamma_se &lt;- predict(object = conc_model_gamma,\n                          newdata = pred_grid,\n                          type = \"link\", # stay in link space\n                          se.fit = TRUE)\n\n# Apply segmented model to simulated values\nconc_model_seg_se&lt;- predict(object = conc_model_seg,\n                          newdata = pred_grid,\n                          type = \"link\", # stay in link space\n                          se.fit = TRUE)\n\n\n\nStep 3: Using predicted values to plot Gamma distribution.\nIn the subsequent plots, three sediment values are plotted (50, 100, and 150). These are used as representations of the way sediment concentration affects the relationship between water and biota trace-element concentrations. It is important to note that sediment IS a continuous variable, the values extracted simply act as examples.\nRaw concentration data is plotted in blue.\nThe following code extracts the predicted concentrations from conc_model_gamma_se results, as well as the 95% confidence intervals for both the predicted values and our real data.\n\n# Add data columns corresponding to predicted values\n# Starting in link space and then using exp() to get to response space\nconcentration_pred &lt;- pred_grid %&gt;% \n  mutate(\n    # log of predicted concentration values\n    log_conc = conc_model_gamma_se$fit,\n    \n    # 95% CI of concentration predictionvalues in link space\n    log_conc_se = conc_model_gamma_se$se.fit,\n    log_conc_lwr = qnorm(0.025, mean = log_conc, sd = log_conc_se),\n    log_conc_upr = qnorm(0.975, mean = log_conc, sd = log_conc_se),\n    \n    # undo the link function -- in this case log --  using exp()\n    conc = exp(log_conc),\n    conc_lwr = exp(log_conc_lwr),\n    conc_upr = exp(log_conc_upr))\n\n\n\n\n\n\n\n\n\n\n\n# Calculate shape and scale for gamma distribution ribbons in plot\nshape &lt;- (concentration_pred$conc^2)/var(concentration_pred$conc)\nscale &lt;- var(concentration_pred$conc)/concentration_pred$conc\n\n# 95% CI of actual data (using gamma distribution)\nconcentration_pred &lt;- concentration_pred %&gt;% \n  mutate(\n    conc_lwr_gamma = qgamma(0.025, shape = shape, scale = scale),\n    conc_upr_gamma = qgamma(0.975, shape = shape, scale = scale))\n\n\n\n\n\n\n\n\n\n\nThe plots above are an intermediary step before the application and plotting of the segmented model.\n\n\nStep 4: Use predicted values to plot segmented distribution.\nIn a similar manner to the code above, columns are added to the prediction grid using the results of conc_model_seg_se. The following plot is created, with a break-point at x = 11.\nThe segmented model is typically presented in log space, as it is the log of the response variable that appears like linear piece-wise function (i.e., as a break-point).\n\n\n\n\n\n\n\n\n\nTo better visualize the Gamma relationship we are exporing, response space is plotted below (the same break-point is visible, but now the relationship between predictor and response is not linear, but exponential)."
  },
  {
    "objectID": "blog/stats-proj/index.html#interpretation",
    "href": "blog/stats-proj/index.html#interpretation",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Interpretation",
    "text": "Interpretation\nVisually, it appears that both a positive relationship and a break-point exist between arsenic concentration in water and biota. To confirm, we can take a look at the model summary outputs.\n\n# Return the coefficients and their statistical significance\nconc_model_gamma$coefficients\n\n\n\n\n\n\n\n\n\nGamma Model Summary\n\n\nCoefficients:\nEstimate\nPr(&gt;|t|)\n\n\n\n\nconcentration_water\n0.080041\n&lt; 2e-16 ***\n\n\nconcentration_sediment\n0.007747\n3.5e-11 ***\n\n\n\n\n\n\n\n\n# Return break-points\nconc_model_seg$psi\n\n\n\n\n\n\n\n\n\nSegmented Model Summary: Break-point\n\n\nBreak-point\nInitial\nEst.\nSt. Err\n\n\n\n\npsi1.concentration_water\nNA\n11.00022\n0.3708171\n\n\n\n\n\n\n\n\n# Return coefficients before and after breakpoints\nconc_model_seg$coefficients\n\n\n\n\n\n\n\n\n\nSegmented Model Summary: Coefficients\n\n\nCoefficients\nEstimate\nPr(&gt;|t|)\n\n\n\n\nconcentration_water\n-0.027325\n1.45e-05 ***\n\n\nU1.concentration_water\n0.229316\nNA\n\n\n\n\n\n\n\nThese outputs correspond to the questions we asked at the beginning:\n1. Does trace-element concentration in water increase trace-element concentration in invertebrates?\nThe concentration_water coefficient of our gamma model returns a value of 0.08, which is significant at a 99% confidence level. We can reject our null hypothesis that there is no relationship between water and invertebrate trace-element concentration.\n2. Is the risk of trace-element contamination/ingestion constant across the whole range of concentrations in sediment and water?\n3. If the risk is sediment/water-concentration dependent, does a threshold value exist?\nOur segmented model returns a break-point of concentration_water = 11. Additionally, the slopes before and after the break-point (-0.03 and 0.23 respectively) are both significant at the 99% confidence level. Thus, we can reject the second part of our null hypothesis, that the relationship between trace-element water and invertebrate concentration stays consistent across all values."
  },
  {
    "objectID": "blog/stats-proj/index.html#other-trace-elements",
    "href": "blog/stats-proj/index.html#other-trace-elements",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Other Trace-Elements",
    "text": "Other Trace-Elements\nPlots of the remaining trace-elements — copper and lead — are below with their corresponding break-point and Gamma coefficient values.\n\nCopper\nGamma Model\n\n\n\n\n\n\n\n\n\nBreak-point Model\n\n\n\n\n\n\n\n\n\nFrom these figures and the coefficients produced by the model, we reject our null hypothesis that there is no relationship between copper concentration in water and invertebrate tissue. Additionally, we reject the null hypothesis that there is no break-point at which the relationship between the response and predictor changes.\nDue to the significance of our Gamma model coefficient, we can say that the probability that this relationship occurred by chance is incredibly low.\n\n\nLead\nGamma Model\n\n\n\n\n\n\n\n\n\nBreak-point Model\n\n\n\n\n\n\n\n\n\nFrom these figures and the coefficients produced by the model, we fail to reject our null hypothesis that there is no relationship between lead concentration in water and invertebrate tissue. However, we can reject the null hypothesis that there is no break-point at which the relationship between the response and predictor changes, as the segmented model still identified one.\nSince the break-point was determined by an insignificant Gamma model, we must be cautious using these results."
  },
  {
    "objectID": "blog/stats-proj/index.html#conclusion",
    "href": "blog/stats-proj/index.html#conclusion",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "Conclusion",
    "text": "Conclusion\nIn this blog post, we walked through how to simulate data for as well as run the Gamma and segmented statistical models on trace-element data from the Clark Fork Basin in Montana.\nIn our analysis, we explored three elements — arsenic, copper, and lead — that when accumulated at high levels, have significant detrimental impact on aquatic ecosystems (especially as their concentrations increase up the food web). Our results suggest that arsenic and copper both contain break-point values at which their accumulation in invertebrate tissue changes in rate based on their concentrations in water. In arsenic this change is a positive one, whereas in copper the relationship levels off. We found no significant relationship between lead concentration in water and invertebrate tissue.\nIn terms of habitat remediation, recommendations based on these results could include paying particular attention to arsenic concentrations in the water."
  },
  {
    "objectID": "blog/stats-proj/index.html#references",
    "href": "blog/stats-proj/index.html#references",
    "title": "Trace-Element Accumulation in Invertebrate Tissue",
    "section": "References",
    "text": "References\nClark, G., Hornberger, M., Hepler, E., & Heinert, T. (2022). Water-quality, bed-sediment, and invertebrate tissue trace-element concentrations for tributaries in the Clark Fork Basin, Montana, October 2019–September 2020 (Report 2022–1090; Open-File Report, p. 30). USGS Publications Warehouse. https://doi.org/10.3133/ofr20221090\nClark, G.D., Hornberger, M.I., Hepler, E.J., and Heinert, T.L., 2022, Water-Quality, Bed-Sediment, and Invertebrate Tissue Trace-Element Concentrations for Tributaries in the Clark Fork Basin, Montana, October 2019–September 2020: U.S. Geological Survey data release, https://doi.org/10.5066/P93BP9P8.\nHaas, M., Pánik, P. Long-Term and Seasonal Trends in the Mode of Accumulation of Elements in the Bodies of Aquatic Insect Larvae. Arch Environ Contam Toxicol 89, 136–153 (2025). https://doi.org/10.1007/s00244-025-01144-7\nHlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.3. https://CRAN.R-project.org/package=stargazer\nPastorino, P., Bertoli, M., Squadrone, S., Brizio, P., Piazza, G., Oss Noser, A. G., Prearo, M., Abete, M. C., & Pizzul, E. (2019). Detection of trace elements in freshwater macrobenthic invertebrates of different functional feeding guilds: A case study in Northeast Italy. Ecohydrology & Hydrobiology, 19(3), 428–440. https://doi.org/10.1016/j.ecohyd.2019.04.006\nRosso, J. J., Schenone, N. F., Pérez Carrera, A., & Fernandez Cirelli, A. (2013). Concentration of arsenic in water, sediments and fish species from naturally contaminated rivers. Environmental geochemistry and health, 35(2), 201-214."
  },
  {
    "objectID": "blog/la-fire-analysis/index.html",
    "href": "blog/la-fire-analysis/index.html",
    "title": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis",
    "section": "",
    "text": "Figure 1: Destroyed homes in Altadena, CA (Image Source: Philip Cheung for The New York Times)\nThis blog post summarizes analyses involving the Eaton and Palisades Fires that took place in Los Angeles County during January 2025. It will specifically highlight the vegetation damage through false color imagery and explore internet availability of census blocks affected by the fires.\nComplete code can be found in the corresponding Github repository."
  },
  {
    "objectID": "blog/la-fire-analysis/index.html#overview",
    "href": "blog/la-fire-analysis/index.html#overview",
    "title": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis",
    "section": "Overview",
    "text": "Overview\nThe Eaton and Palisades fires occurred nearly simultaneously, inflicting both ecological and infrastructural damage on Los Angeles. Together, they destroyed more than 16,000 structures and displaced thousands of households. Understanding the specifics of the impact – such as which populations were most affected as well as the extent of vegetation damage – is vital for recovery efforts, as well as informing future fire safety and policy.\nWe overlay the fire perimeters onto to remote sensing and Environmental Justice Index (EJI) data to explore the patterns within. First, by using remote sensing data and assigning infrared bands to visible colors, we are able to highlight vegetation health, burn severity, and the extent of fire scars remnant after the fire. Second, clipping EJI census block data to the fire perimeters gives us a summary of the internet availability in each area. Internet availability is an important aspect of fire safety response as communities that lack availability to natural disaster information have less time to respond.\n\nAnalysis Highlights\n\nUsing xarray and NetCDF data formats. Our primary dataset comes from the NASA/USGS Landsat program, and must be read in using the xarray package.\nPlotting raster data as false color. The method combination .plot.imshow, the argument robust, and selecting reflectance bands other than true color are important steps in the process.\nClipping raster data to a polygon. geopandas functionality is used to accurately clip EJI data to our area of interest.\n\n\n\nAbout the Data\nLandsat/remote sensing\nThe dataset used in this analysis is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmospherically-corrected surface reflectance data, collected by the Landsat 8 satellite. Landsat data is provided by a series of Earth-observing satellites jointly managed by NASA and the U.S. Geological Survey (USGS), and stores a significant amount of reflectance information about the Earth’s surface.\nThe data was retrieved from the Microsoft Planetary Computer data catalogue catalogue and clipped to an area surrounding the fire perimeters by the EDS220 course team.\nPalisades and Eaton fire perimeter\nPalisades and Eaton fire perimeter data were sourced from LA County’s GIS hub. It contains dissolved fire boundaries for Eaton and Palisades fires. It is a public data set, published January 21, 2025 and last updated on February 26, 2025.\nEnvironmental Justice Index (EJI)\nEJI aims to summarize the cumulative impacts of environmental injustice by census tract in the United States. The index considers 36 different environmental, social, and health variables, with data from a variety of sources (including but not limited to the U.S. Census Bureau, the U.S. Environmental Protection Agency, USGS, and OpenStreetMap). The data in this analysis was sourced from the Centers for Disease Control and Prevention and Agency for Toxic Substances Disease Registry."
  },
  {
    "objectID": "blog/la-fire-analysis/index.html#analysis",
    "href": "blog/la-fire-analysis/index.html#analysis",
    "title": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis",
    "section": "Analysis",
    "text": "Analysis\n\nSetup\n\n# Import necessary libraries\nimport os\nimport geopandas as gpd\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n\n\nFalse Color Image\n\nFire Perimeter Data Exploration\nBefore we utilize our fire perimeter datasets, we want to ensure that we have a general sense of what they contain and how they look.\n\n# Read in data, using os to build file path and geopandas to read in .shp files (one for each fire)\n\n# Eaton perimeter\nfp = os.path.join('data','Eaton_Perimeter_20250121','Eaton_Perimeter_20250121.shp')\neaton_perimeter = gpd.read_file(fp)\n\n# Palisades perimeter\nfp = os.path.join('data','Palisades_Perimeter_20250121','Palisades_Perimeter_20250121.shp')\npalisades_perimeter = gpd.read_file(fp)\n\nData loaded in successfully! Now we can plot them to visualize what we are working with.\n\n\nCode\n# Plot perimeter data to visualize its contents\n\n# Initialize figure with two axes (so can plot each perimeter on a separate plot)\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (6,4))\n\n# And the Palisades fire perimeter on the left //.boundary allows access to just the border of the polygon\npalisades_perimeter.boundary.plot(ax = ax[0])\n\n# Plot Eaton fire perimeter on the right \neaton_perimeter.boundary.plot(ax = ax[1])\n\n\n\n\n\n\n\n\n\nNow we have a preliminary understanding of what our datasets contain: complete geometries of each fire perimeter.\nTo find the CRS of the two datasets (which will inform how we treat them while plotting other data), we can explore the following.\n\n# Use an assert statement to confirm the two data sets have the same CRS\nassert eaton_perimeter.crs == palisades_perimeter.crs\n\n# Since they match, what is the CRS of both fires?\nprint(f\"The CRS of the fire perimeter data is {eaton_perimeter.crs}.\")\n\nThe CRS of the fire perimeter data is EPSG:3857.\n\n\nGreat! The two CRSs match, and we will keep this information in mind when we plot with our raster data.\n\n\nLandsat (NetCDF) Data Import and Exploration\nSimilarly to our fire perimeter data, we want to read in our remote sensing data and take a look at its features, such as dimensions, variables, and attributes. We are using xarray in this case.\n\n# Read in data, using os to build file path\nfp = os.path.join('data', 'landsat8-2025-02-23-palisades-eaton.nc')\n\n# Import landsat data using `xr.open_dataset()` from the xarray library\nlandsat = xr.open_dataset(fp, engine=\"netcdf4\")\n\nLet’s take a look at the xarray object itself.\n\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 78MB\nDimensions:      (y: 1418, x: 2742)\nCoordinates:\n  * y            (y) float64 11kB 3.799e+06 3.799e+06 ... 3.757e+06 3.757e+06\n  * x            (x) float64 22kB 3.344e+05 3.344e+05 ... 4.166e+05 4.166e+05\n    time         datetime64[ns] 8B ...\nData variables:\n    red          (y, x) float32 16MB ...\n    green        (y, x) float32 16MB ...\n    blue         (y, x) float32 16MB ...\n    nir08        (y, x) float32 16MB ...\n    swir22       (y, x) float32 16MB ...\n    spatial_ref  int64 8B ...xarray.DatasetDimensions:y: 1418x: 2742Coordinates: (3)y(y)float643.799e+06 3.799e+06 ... 3.757e+06units :metreresolution :-30.0crs :EPSG:32611axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinatearray([3799050., 3799020., 3798990., ..., 3756600., 3756570., 3756540.])x(x)float643.344e+05 3.344e+05 ... 4.166e+05units :metreresolution :30.0crs :EPSG:32611axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinatearray([334410., 334440., 334470., ..., 416580., 416610., 416640.])time()datetime64[ns]...[1 values with dtype=datetime64[ns]]Data variables: (6)red(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]green(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]blue(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]nir08(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]swir22(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]spatial_ref()int64...crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :334395.0 30.0 0.0 3799065.0 0.0 -30.0[1 values with dtype=int64]Indexes: (2)yPandasIndexPandasIndex(Index([3799050.0, 3799020.0, 3798990.0, 3798960.0, 3798930.0, 3798900.0,\n       3798870.0, 3798840.0, 3798810.0, 3798780.0,\n       ...\n       3756810.0, 3756780.0, 3756750.0, 3756720.0, 3756690.0, 3756660.0,\n       3756630.0, 3756600.0, 3756570.0, 3756540.0],\n      dtype='float64', name='y', length=1418))xPandasIndexPandasIndex(Index([334410.0, 334440.0, 334470.0, 334500.0, 334530.0, 334560.0, 334590.0,\n       334620.0, 334650.0, 334680.0,\n       ...\n       416370.0, 416400.0, 416430.0, 416460.0, 416490.0, 416520.0, 416550.0,\n       416580.0, 416610.0, 416640.0],\n      dtype='float64', name='x', length=2742))Attributes: (0)\n\n\nFrom this output, we can see the five reflectance bands that our data has stored. We also see that there are three coordinates: x, y, and datetime. We now also know the size of our coordinates and the data type of each variable.\nWe can check the geographic information of our data using the rio accessor…\n\nprint('CRS: ', landsat.rio.crs)\n\nCRS:  None\n\n\n… but get nothing back. This is because this data currently has no geographic information, as it is stored within the spatial_ref variable. We can restore it by doing the following.\n\n# Access CRS through `spatial_ref` variable\n# .crs_wkt specifies that our CRS was stored in the well-known text format\nlandsat_crs = landsat.spatial_ref.crs_wkt\n\n# Recover and reassign geospatial info through .write_crs\nlandsat_geo = landsat.rio.write_crs(landsat_crs)\n\n# Print new CRS info\nprint(f\"The CRS of the landsat raster data is {landsat_geo.rio.crs}.\")\n\nThe CRS of the landsat raster data is EPSG:32611.\n\n\nSuccess!\n\n\nFalse Color Image\nFalse color images use colors not found in visible light, such as infrared, which are assigned to different bands of the visible light spectrum (RGB). This helps us visualize phenomenom that can be observed with reflectance patterns, but not by the human eye.\nHere, we create a false color image by plotting the short-wave infrared (swir22), near-infrared, and red variables (in that order). We do this because those three wavelengths are useful in determining vegetation health. Then, we can overlay our fire perimeters to explore differences between affected and untouched areas.\nFirst, we want to make sure our geographic information matches.\n\n# Changing fire perimeter data to the landsat CRS ; sourced from original exploration, where landsat_crs = 'epsg:32611'\neaton_perimeter = eaton_perimeter.to_crs(landsat_crs)\npalisades_perimeter = palisades_perimeter.to_crs(landsat_crs)\n\nThen, we can plot them all together.\nNote:\nimshow() is useful for raster data as it tells the “image to show”, and the argument robust = True indicates to only plot values from the 2nd to 98th percentile. This distinction helps to avoid outliers that are results of inaccurate or incorrect data (for example: extremely low or high values that correspond to cloud cover) which can skew the appearance of the image, sometimes inhibiting it from plotting at all.\n\n\nCode\n# Initialize figure with one axes\nfig, ax = plt.subplots(figsize = (9,5))\n\n# Plot false color raster image by selecting which bands we want to assign\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True,\n                                                           ax = ax)\n\n# Plot the Eaton fire perimeter\neaton_perimeter.boundary.plot(ax = ax,\n                              color = \"red\",\n                              linewidth = 1.5,\n                              label = \"Fire Perimeter\")             # Set label to create legend for fire perimeter\n\n# Plot the Palisades fire perimeter\npalisades_perimeter.boundary.plot(ax = ax,\n                                  color = \"red\",\n                                  linewidth = 1.5)\n\n# Add labels to distinguish between Eaton and Palisades boundaries\n# .set_bbox() creates background for text (for better visibility)\nax.text(x = 402400, y = 3779000, s = \"Eaton\", color = \"black\", fontsize = 8).set_bbox(dict(facecolor='white', alpha = 0.8, edgecolor = 'none'))\nax.text(x = 345000, y = 3775000, s = \"Palisades\", color = \"black\", fontsize = 8).set_bbox(dict(facecolor='white', alpha = 0.8, edgecolor = 'none'))\n\n# Turn of x and y axis (are in meters, so don't tell give us a lot of information)\nax.axis('off')\n\n# Plot title and description\nplt.title(\"False Color Image of Los Angeles County, Post January 2025 Fires\")\nplt.figtext(x = 0.5, y = 0, s= \"Description: False color imagery, overlayed with known fire perimeters, \"\n                                \"is used to highlight the effects of wildfires on LA county.\" \\\n                                \" By plotting short-wave infrared (swir22), near-infrared, and red reflectance bands,\" \\\n                                \"we are able to observe the stark contrast in features such as vegetation health and burn severity throughout the area.\",\n            ha=\"center\", fontsize=10, wrap=True)\n\n# Add legend (for fire perimeters)\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nNow that we have a false color image with the fires highlighted, we can see the difference in vegetation health between areas within and outside the fire perimeters.\n\n\n\nInternet Availability\nLoad in EJI data using geopandas.\n\neji = gpd.read_file(\"data/EJI_2024_California/EJI_2024_California.gdb\")\n\n\nPolygon Clipping\nThe EJI dataset is a raster spanning all of California. To get it to only our area of interest (the fires), we can use the geopandas methods .sjoin() and .clip().\n\n# Transform both perimeters to have CRSs matching that of the EJI data \npalisades_perimeter = palisades_perimeter.to_crs(eji.crs)\neaton_perimeter = eaton_perimeter.to_crs(eji.crs)\n\nFirst, we complete a spatial join of our EJI and fire perimeter data. The result is the EJI census tracts that intersect with the Palisades and Eaton fire perimeters.\nSpatial Join:\n\n# Inner join fire perimeter to CA census tracts\npalisades_tracts = gpd.sjoin(eji, palisades_perimeter, how = \"inner\", predicate = \"intersects\")\neaton_tracts = gpd.sjoin(eji, eaton_perimeter, how = \"inner\", predicate = \"intersects\")\n\nThrough the order of our arguments, we told .sjoin() that we only want EJI that intersects with the fire perimeters. The argument “inner” specifies that we want to keep only the data that is shared between both EJI and the two fire perimeters.\nWe can visualization this in the following plot:\n\n\nCode\n# Initialize plot with two axes\nig, ax = plt.subplots(figsize=(9,5), nrows = 1, ncols = 2)\n\n# Plot census tracts that intersect with the fire perimeter\npalisades_tracts.plot(ax = ax[0])\n# Plot palisades fire perimeter on top in red\npalisades_perimeter.boundary.plot(ax = ax[0],\n                       color = \"red\")\n\n# Plot census tracts that intersect with fire perimeter\neaton_tracts.plot(ax = ax[1])\n# Plot eaton fire perimeter on top in red\neaton_perimeter.boundary.plot(ax = ax[1],\n                       color = \"red\")\n\n\n\n\n\n\n\n\n\nWe only want the data that is fully within the fire perimeters, so additional steps must be taken.\nOne option to conduct a similar spatial join (using .sjoin()), but instead of the predicate = \"intersects\", specify predicate = \"within\". This distinction tells the method to only keep data that is wholly within our perimeters, instead of just intersecting.\nIn this analysis, however, we opt to use the geopandas .clip() method.\nClipping:\n\n# First arg: what we want to clip; Second arg: what polygon we want to clip to\nclipped_palisades = gpd.clip(eji, palisades_perimeter)\nclipped_eaton = gpd.clip(eji, eaton_perimeter)\n\nTo ensure that our clipping was successful, we can plot our new clipped data with our fire perimeters.\n\n\nCode\n# Initialize plot with two axes, plot eaton and palisades on each\nig, ax = plt.subplots(figsize=(9,5), nrows = 1, ncols = 2)\n\n## Palisades\n# Plot clipped data\nclipped_palisades.plot(ax = ax[0])\n# Fire periemeter\npalisades_perimeter.boundary.plot(ax = ax[0],\n                       color = \"red\")\n\n## Eaton\n# Clipped data\nclipped_eaton.plot(ax = ax[1])\n# Fire perimeter\neaton_perimeter.boundary.plot(ax = ax[1],\n                       color = \"red\")\n\n\n\n\n\n\n\n\n\nWe have successfully extracted only the EJI/census data that is contained by our two fire perimeters!\n\n\nVisualizing EJI Data\nIn plotting our EJI variable of interest within our fire perimeters, we have to select our variable of interest. In our case this is internet availability. Variable names for the EJI data can be found in its metadata.\n\n# Specify internet availability information as variable of interest\neji_variable = 'E_NOINT'\n\nWe can take then plot our clipped eji datasets (clipped_eaton and clipped_palisades), and specify column = eji_variable to color each census block by socioeconomic information.\n\n\nCode\n# Initilaize figure\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))\n\n# Find common min/max for legend range\nvmin = min(clipped_palisades['E_NOINT'].min(), clipped_eaton['E_NOINT'].min())\nvmax = max(clipped_palisades['E_NOINT'].max(), clipped_eaton['E_NOINT'].max())\n\n# Plot census tracts within Palisades perimeter\nclipped_palisades.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1)\n\nax1.set_title('Palisades Fire')\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nclipped_eaton.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2)\n\nax2.set_title('Eaton Fire')\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Persons with No Internet - Fire Areas Comparison', fontsize = 16)\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Persons with No Internet (%)')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nFrom this plot, we can see that there are few census tract with a significant percentage of individuals who do not have internet access. The left-most census tract of the Eaton fire – colored in yellow – is perhaps of concern.\nWe can ask the question, why is internet availability lower there than in the surrounding areas? And, how did that affect their response to the LA fires?"
  },
  {
    "objectID": "blog/la-fire-analysis/index.html#conclusion",
    "href": "blog/la-fire-analysis/index.html#conclusion",
    "title": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nThis blog post used Python libraries such as xarray and geopandas to perform spatial analyses related to the Los Angeles County fires of January 2025. The images produced revealed the intensity of vegetation damage on the affected area, as well as raised questions regarding resource access inequality in areas impacted by the fires.\nThank you for reading!"
  },
  {
    "objectID": "blog/la-fire-analysis/index.html#references",
    "href": "blog/la-fire-analysis/index.html#references",
    "title": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis",
    "section": "References",
    "text": "References\nCenters for Disease Control and Prevention and Agency for Toxic Substances Disease Registry. (2024). Environmental Justice Index. Accessed November 21, 2025. https://atsdr.cdc.gov/place-health/php/eji/eji-data-download.html\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8–9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2 [Dataset]. U.S. Geological Survey. Accessed November 15, 2025. https://doi.org/10.5066/P9OGBGM6\nLos Angeles County Enterprise GIS. (2025). Palisades and Eaton Dissolved Fire Perimeters [Dataset]. Los Angeles County. Accessed November 21, 2025. https://egis-lacounty.hub.arcgis.com/maps/ad51845ea5fb4eb483bc2a7c38b2370c/about\nPhillips, S. (2025, February). The Palisades and Eaton Fires: Neighborhood Data and Potential Housing Market Effects. UCLA Lewis Center for Regional Policy Studies."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Los Angeles Fires: Vegetation Health & Socioeconomic Analysis\n\n\n\nPython\n\ngeospatial\n\n\n\nUsing multispectral and EJI data to explore aspects of the Eaton and Palisades fires.\n\n\n\nSofia Sarak\n\n\nDec 11, 2025\n\n\n\n\n\n\n\n\n\n\n\nWhere Can I Farm this Marine Species?\n\n\n\nR\n\ngeospatial\n\n\n\nBuilding an R function to determine aquaculture suitability on the West Coast.\n\n\n\nSofia Sarak\n\n\nDec 10, 2025\n\n\n\n\n\n\n\n\n\n\n\nTrace-Element Accumulation in Invertebrate Tissue\n\n\n\nR\n\nstatistics\n\n\n\nUsing Gamma and segmented regression to find relationships and break-points.\n\n\n\nSofia Sarak\n\n\nDec 9, 2025\n\n\n\n\n\n\nNo matching items"
  }
]